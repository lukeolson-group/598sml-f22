{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f852394-c13c-497c-98fc-173c1e704cb1",
   "metadata": {},
   "source": [
    "# Derivatives ... starting with regression\n",
    "\n",
    "Links:\n",
    "- https://datahacker.rs/003-pytorch-how-to-implement-linear-regression-in-pytorch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1940dfb-28c8-470e-a4a7-7475ff151e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370466a6-8906-434f-8243-6a3761c08ee9",
   "metadata": {},
   "source": [
    "First let's create the observed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63cde09-ce8a-4451-880b-4cb25b4a6621",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(1,10, dtype=np.float64)\n",
    "y = 2 * x_true + 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfb37bd-cd9b-4ee9-b28d-ec0d5844b1f0",
   "metadata": {},
   "source": [
    "Now consider a *linear* model with a single paramater:\n",
    "$$\n",
    "y = a x\n",
    "$$\n",
    "\n",
    "If we try a model with say $a_1$, then we have $\\hat{y}_1 = a_1 x$ so that\n",
    "$$\n",
    "\\hat{y}_1 - y = a_1 x_{true} - 2 x_{true}\n",
    "$$\n",
    "is the error.\n",
    "\n",
    "Next, we want to try a bunch of $a_i$ and minimize\n",
    "$$\n",
    "loss = (\\hat{y} - y)^2\n",
    "$$\n",
    "or through cost as\n",
    "$$\n",
    "cost = \\frac{1}{N}\\sum_{n=1}^{N}(\\hat{y}_n - y_n)^2\n",
    "$$\n",
    "where $N$ is the number of observed points (`len(y)`)\n",
    "(of course, for this model we could use least-squares to find the minimum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dde17e-21df-4729-af11-dd03c62f0102",
   "metadata": {},
   "source": [
    "Let's try this..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c1e493-a9ac-408f-9176-b5af4412de28",
   "metadata": {},
   "outputs": [],
   "source": [
    "alist = np.linspace(0,4,50)\n",
    "cost = np.zeros(len(alist))\n",
    "\n",
    "for i, a in enumerate(alist):\n",
    "    loss = a*x - y\n",
    "    cost[i] = (1/len(y)) * np.sum(loss)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f15e342-c4b4-4e04-b131-1d9923fca356",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(alist, cost, 'o-')\n",
    "ax.set_xlabel('$a_i$')\n",
    "ax.set_ylabel('cost')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fc4286-9cf8-4f4c-bcaf-fd1aa93d26bf",
   "metadata": {},
   "source": [
    "A little match helps a lot...\n",
    "\n",
    "Let $J$ be the cost:\n",
    "$$\n",
    "J = \\sum_n (a x_n - y_n)^2\n",
    "$$\n",
    "\n",
    "Then minimizing the loss over $a$ we need the derivative:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial J}{\\partial a}\n",
    "&= \\frac{1}{N} \\sum_n \\frac{\\partial}{\\partial a} (a x_n - y_n)\\\\\n",
    "&= \\frac{1}{N}\\sum_n 2(ax_n-y_n)\\frac{\\partial}{\\partial a}(a x_n - y_n)\\\\\n",
    "&= \\frac{1}{N}\\sum_n 2(ax_n-y_n)(x_n - 0)\\\\\n",
    "&= \\frac{1}{N}\\sum_n 2x_n (ax_n-y_n)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Now, we check an $a_i$, and compute the gradient to see if we need to increase or decrease $a_i$ to create the model.  How much?  This is the learning rate:\n",
    "$$\n",
    "a_{i+1} = a_i - \\alpha \\frac{\\partial J}{\\partial a}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2da1b35-b3b6-4676-9597-1cc2ecb2ef0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xt = torch.from_numpy(x).reshape(-1,1)\n",
    "yt = torch.from_numpy(y).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216e6863-5961-40f8-90cd-44a0711f1a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Linear(1, 1, bias=False, dtype=torch.float64)\n",
    "loss = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba16333-0d00-4a4f-85b3-7511a3a16f5d",
   "metadata": {},
   "source": [
    "Train the model... 1000 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f2e9e6-4d98-48f0-8032-875a6473ce8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_history = []\n",
    "\n",
    "for epock in range(1000):\n",
    "    yhat = model(xt)\n",
    "    \n",
    "    output = loss(yhat, yt)\n",
    "    output.backward()  # computes dloss/da\n",
    "    cost_history.append(output.item())\n",
    "    \n",
    "    optimizer.step()   # a <- a - 0.01 dloss/da\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebad30e4-c31f-467d-a4fc-ce131d032fb0",
   "metadata": {},
   "source": [
    "This all looks complex for a simple model!\n",
    "\n",
    "Let's try finding $a$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6deee870-c3e5-44f1-b134-4b2ae3e18869",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = model.forward(xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1265abc-a17c-4951-ae19-1d4e20f93339",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(xt, yt, 'o', color='tab:red')\n",
    "plt.plot(xt, y_predicted.detach().numpy(), '--')\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "  print(name, param)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
